{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: VCD-Net training \n",
    "\n",
    "This notebook demonstrates how to train a VCD-Net on a given dataset, which is assumed to be prepared by [datapre notebook](../datapre/datapre.ipynb) in our datapre package. \n",
    "\n",
    "### Notes on dataset in this demo\n",
    "After you go through [datapre notebook](../datapre/datapre.ipynb), the dataset should be stored in */results/TrainingPair*. We also provide a dataset generated in advance [here](https://drive.google.com/file/d/1h_Q7ylHeMh9dCUeo8Fz8o2j0WsM25-2g/view?usp=sharing) (under data/train/), in case you want to skip the data preparation step. By default, this notebook assumes that the data for training has been located under *./data/train*. You can always change the file path in the [configuration script](./config.py) to alter the target dataset though. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the parameters\n",
    "We define all parameters in a [configuration script](./config.py). Make the edit according to specific application and dataset before running this notebook.  \n",
    "\n",
    "Typical parameters include:\n",
    "- **img_size** : the lateral pixel size of the input patch, assuming it's square \n",
    "- **PSF.n_slices** : number of z slices of targeted 3-D reconstruction\n",
    "- **PSF.Nnum**     : number of pixels behind each lenslet\n",
    "- **label**        : label for folder naming\n",
    "- **TRAIN.target3d_path** : folder where the 3D HR patches are stored \n",
    "- **TRAIN.lf2d_path**     : folder where the 2D light field patches are stored\n",
    "- **TRAIN.n_epoch**       : number of epochs for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/tensorlayer/layers/core.py:43: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/tensorlayer/layers/pooling.py:59: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Parameters defined in config.py:\n",
      "    size_factor                      [1, 1]\n",
      "    img_size                         176\n",
      "    label                            tubulin_40x_n11_[m30-30]_step1um_xl9_num120_sparse\n",
      "    model                            structure\n",
      "    n_channels                       1\n",
      "PSF related: \n",
      "    Nnum                             11                            \n",
      "    n_slices                         61                            \n",
      "Training related: \n",
      "    target3d_path                    ../../data/TrainingPair/WF/   \n",
      "    valid_on_the_fly                 0                             \n",
      "    log_dir                          ./log/tubulin_40x_n11_[m30-30]_step1um_xl9_num120_sparse/\n",
      "    lr_decay                         0.1                           \n",
      "    using_edge_loss                  0                             \n",
      "    device                           0                             \n",
      "    lr_init                          0.0001                        \n",
      "    beta1                            0.9                           \n",
      "    n_epoch                          200                           \n",
      "    test_saving_path                 ./sample/test/tubulin_40x_n11_[m30-30]_step1um_xl9_num120_sparse/\n",
      "    batch_size                       1                             \n",
      "    decay_every                      50                            \n",
      "    ckpt_dir                         ./checkpoint/tubulin_40x_n11_[m30-30]_step1um_xl9_num120_sparse/\n",
      "    lf2d_path                        ../../data/TrainingPair/LF/   \n",
      "    ckpt_saving_interval             10                            \n"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset\n",
    "from train import Trainer\n",
    "from config import config\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Parameters defined in config.py:\")\n",
    "for par, val in config.items():\n",
    "    if not type(config[par]) == type(config):\n",
    "        print('    {:<30}   {:}'.format(par,val))\n",
    "\n",
    "print(\"PSF related: \")\n",
    "for par, val in config.PSF.items():\n",
    "    print('    {:<30}   {:<30}'.format(par,val))\n",
    "    \n",
    "print(\"Training related: \")\n",
    "for par, val in config.TRAIN.items():\n",
    "    print('    {:<30}   {:<30}'.format(par,val))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the VCD-Net\n",
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_size         = config.img_size * np.array(config.size_factor) \n",
    "n_num            = config.PSF.Nnum\n",
    "base_size        = img_size // n_num # lateral size of lf_extra\n",
    "training_dataset = Dataset(config.TRAIN.target3d_path, config.TRAIN.lf2d_path, config.PSF.n_slices, \n",
    "                           config.PSF.Nnum, base_size, normalize_mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training\n",
    "**This step takes long time.** Due to limitation in environment setup on code ocean (when dealing with both Matlab and Tensorflow), we trade-off to **use CPU** for this demonstration. Note that you can use GPU for better performance on your local machine, which we highly recommend. It's encouraged to download the code and test locally to get away with all the limitation on the cloud service.\n",
    "\n",
    "**Important:** For simply reviewing our VCD-LFM pipeline, we suggest you **interrupt** the following training process and directly use the checkpoint we uploaded in */data/checkpoint/* and navigate to the [predict notebook](./predict_demo.ipynb).\n",
    "\n",
    "Try restart the kernel for unpredicted error in this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/train.py:62: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/train.py:65: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/tensorlayer/layers/core.py:386: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  vcdnet/lf_extra: (1, 16, 16, 121)\n",
      "[TL] Conv2dLayer vcdnet/conv1: shape:(7, 7, 121, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/tensorlayer/layers/convolution.py:203: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] SubpixelConv2d  interp/subpixel0: scale: 2 n_out_channel: 32 act: identity\n",
      "[TL] Conv2dLayer vcdnet/interp/conv0: shape:(3, 3, 32, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel1: scale: 2 n_out_channel: 16 act: identity\n",
      "[TL] Conv2dLayer vcdnet/interp/conv1: shape:(3, 3, 16, 32) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel2: scale: 2 n_out_channel: 8 act: identity\n",
      "[TL] Conv2dLayer vcdnet/interp/conv2: shape:(3, 3, 8, 16) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel3: scale: 2 n_out_channel: 4 act: identity\n",
      "[TL] Conv2dLayer vcdnet/interp/conv3: shape:(3, 3, 4, 8) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] Conv2dLayer vcdnet/interp/conv_final: shape:(3, 3, 8, 8) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/interp/bn_final: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] Conv2dLayer vcdnet/encoder/conv0: shape:(3, 3, 8, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/encoder/bn_0: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 0 : (1, 256, 256, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Conv2dLayer vcdnet/encoder/conv1: shape:(3, 3, 64, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/encoder/bn1: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer vcdnet/encoder/add1: size:(1, 256, 256, 128) fn:add\n",
      "[TL] PoolLayer   vcdnet/encoder/maxplool1: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer vcdnet/encoder/conv2: shape:(3, 3, 128, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/encoder/bn2: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer vcdnet/encoder/add2: size:(1, 128, 128, 256) fn:add\n",
      "[TL] PoolLayer   vcdnet/encoder/maxplool2: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer vcdnet/encoder/conv3: shape:(3, 3, 256, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/encoder/bn3: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer vcdnet/encoder/add3: size:(1, 64, 64, 512) fn:add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 64)\n",
      "(1, 256, 256, 64) (1, 256, 256, 64)\n",
      "encoder 1 : (1, 128, 128, 128)\n",
      "(1, 128, 128, 128)\n",
      "(1, 128, 128, 128) (1, 128, 128, 128)\n",
      "encoder 2 : (1, 64, 64, 256)\n",
      "(1, 64, 64, 256)\n",
      "(1, 64, 64, 256) (1, 64, 64, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] PoolLayer   vcdnet/encoder/maxplool3: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer vcdnet/encoder/conv4: shape:(3, 3, 512, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/encoder/bn4: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 3 : (1, 32, 32, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] ElementwiseLayer vcdnet/encoder/add4: size:(1, 32, 32, 512) fn:add\n",
      "[TL] PoolLayer   vcdnet/encoder/maxplool4: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer vcdnet/encoder/conv5: shape:(3, 3, 512, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/encoder/bn5: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer vcdnet/encoder/add5: size:(1, 16, 16, 512) fn:add\n",
      "[TL] PoolLayer   vcdnet/encoder/maxplool5: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] UpSampling2dLayer upsamplimg: is_scale:False size:(16, 16) method:0 align_corners:False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 512)\n",
      "(1, 32, 32, 512) (1, 32, 32, 0)\n",
      "encoder 4 : (1, 16, 16, 512)\n",
      "(1, 16, 16, 512)\n",
      "(1, 16, 16, 512) (1, 16, 16, 0)\n",
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/tensorlayer/layers/convolution.py:538: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] ConcatLayer vcdnet/decoder/concat1: axis: -1\n",
      "[TL] Conv2dLayer vcdnet/decoder/conv2: shape:(3, 3, 1024, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/decoder/bn2: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg2: is_scale:False size:(32, 32) method:0 align_corners:False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 4 : (1, 16, 16, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] ConcatLayer vcdnet/decoder/concat2: axis: -1\n",
      "[TL] Conv2dLayer vcdnet/decoder/conv3: shape:(3, 3, 1024, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/decoder/bn3: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 3 : (1, 32, 32, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] UpSampling2dLayer upsamplimg3: is_scale:False size:(64, 64) method:0 align_corners:False\n",
      "[TL] ConcatLayer vcdnet/decoder/concat3: axis: -1\n",
      "[TL] Conv2dLayer vcdnet/decoder/conv4: shape:(3, 3, 768, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer vcdnet/decoder/bn4: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg4: is_scale:False size:(128, 128) method:0 align_corners:False\n",
      "[TL] ConcatLayer vcdnet/decoder/concat4: axis: -1\n",
      "[TL] Conv2dLayer vcdnet/decoder/conv5: shape:(3, 3, 384, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 2 : (1, 64, 64, 512)\n",
      "decoder 1 : (1, 128, 128, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] BatchNormLayer vcdnet/decoder/bn5: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg5: is_scale:False size:(256, 256) method:0 align_corners:False\n",
      "[TL] ConcatLayer vcdnet/decoder/concat5: axis: -1\n",
      "[TL] Conv2dLayer vcdnet/decoder/conv6: shape:(3, 3, 192, 61) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 0 : (1, 256, 256, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] BatchNormLayer vcdnet/decoder/bn6: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg6: is_scale:False size:(256, 256) method:0 align_corners:False\n",
      "[TL] UpSampling2dLayer resize_final: is_scale:False size:[176 176] method:0 align_corners:False\n",
      "[TL]   param   0: vcdnet/conv1/W_conv2d:0 (7, 7, 121, 128)    float32_ref\n",
      "[TL]   param   1: vcdnet/interp/conv0/W_conv2d:0 (3, 3, 32, 64)     float32_ref\n",
      "[TL]   param   2: vcdnet/interp/conv1/W_conv2d:0 (3, 3, 16, 32)     float32_ref\n",
      "[TL]   param   3: vcdnet/interp/conv2/W_conv2d:0 (3, 3, 8, 16)      float32_ref\n",
      "[TL]   param   4: vcdnet/interp/conv3/W_conv2d:0 (3, 3, 4, 8)       float32_ref\n",
      "[TL]   param   5: vcdnet/interp/conv_final/W_conv2d:0 (3, 3, 8, 8)       float32_ref\n",
      "[TL]   param   6: vcdnet/interp/bn_final/beta:0 (8,)               float32_ref\n",
      "[TL]   param   7: vcdnet/interp/bn_final/gamma:0 (8,)               float32_ref\n",
      "[TL]   param   8: vcdnet/interp/bn_final/moving_mean:0 (8,)               float32_ref\n",
      "[TL]   param   9: vcdnet/interp/bn_final/moving_variance:0 (8,)               float32_ref\n",
      "[TL]   param  10: vcdnet/encoder/conv0/W_conv2d:0 (3, 3, 8, 64)      float32_ref\n",
      "[TL]   param  11: vcdnet/encoder/bn_0/beta:0 (64,)              float32_ref\n",
      "[TL]   param  12: vcdnet/encoder/bn_0/gamma:0 (64,)              float32_ref\n",
      "[TL]   param  13: vcdnet/encoder/bn_0/moving_mean:0 (64,)              float32_ref\n",
      "[TL]   param  14: vcdnet/encoder/bn_0/moving_variance:0 (64,)              float32_ref\n",
      "[TL]   param  15: vcdnet/encoder/conv1/W_conv2d:0 (3, 3, 64, 128)    float32_ref\n",
      "[TL]   param  16: vcdnet/encoder/bn1/beta:0 (128,)             float32_ref\n",
      "[TL]   param  17: vcdnet/encoder/bn1/gamma:0 (128,)             float32_ref\n",
      "[TL]   param  18: vcdnet/encoder/bn1/moving_mean:0 (128,)             float32_ref\n",
      "[TL]   param  19: vcdnet/encoder/bn1/moving_variance:0 (128,)             float32_ref\n",
      "[TL]   param  20: vcdnet/encoder/conv2/W_conv2d:0 (3, 3, 128, 256)    float32_ref\n",
      "[TL]   param  21: vcdnet/encoder/bn2/beta:0 (256,)             float32_ref\n",
      "[TL]   param  22: vcdnet/encoder/bn2/gamma:0 (256,)             float32_ref\n",
      "[TL]   param  23: vcdnet/encoder/bn2/moving_mean:0 (256,)             float32_ref\n",
      "[TL]   param  24: vcdnet/encoder/bn2/moving_variance:0 (256,)             float32_ref\n",
      "[TL]   param  25: vcdnet/encoder/conv3/W_conv2d:0 (3, 3, 256, 512)    float32_ref\n",
      "[TL]   param  26: vcdnet/encoder/bn3/beta:0 (512,)             float32_ref\n",
      "[TL]   param  27: vcdnet/encoder/bn3/gamma:0 (512,)             float32_ref\n",
      "[TL]   param  28: vcdnet/encoder/bn3/moving_mean:0 (512,)             float32_ref\n",
      "[TL]   param  29: vcdnet/encoder/bn3/moving_variance:0 (512,)             float32_ref\n",
      "[TL]   param  30: vcdnet/encoder/conv4/W_conv2d:0 (3, 3, 512, 512)    float32_ref\n",
      "[TL]   param  31: vcdnet/encoder/bn4/beta:0 (512,)             float32_ref\n",
      "[TL]   param  32: vcdnet/encoder/bn4/gamma:0 (512,)             float32_ref\n",
      "[TL]   param  33: vcdnet/encoder/bn4/moving_mean:0 (512,)             float32_ref\n",
      "[TL]   param  34: vcdnet/encoder/bn4/moving_variance:0 (512,)             float32_ref\n",
      "[TL]   param  35: vcdnet/encoder/conv5/W_conv2d:0 (3, 3, 512, 512)    float32_ref\n",
      "[TL]   param  36: vcdnet/encoder/bn5/beta:0 (512,)             float32_ref\n",
      "[TL]   param  37: vcdnet/encoder/bn5/gamma:0 (512,)             float32_ref\n",
      "[TL]   param  38: vcdnet/encoder/bn5/moving_mean:0 (512,)             float32_ref\n",
      "[TL]   param  39: vcdnet/encoder/bn5/moving_variance:0 (512,)             float32_ref\n",
      "[TL]   param  40: vcdnet/decoder/conv2/W_conv2d:0 (3, 3, 1024, 512)    float32_ref\n",
      "[TL]   param  41: vcdnet/decoder/bn2/beta:0 (512,)             float32_ref\n",
      "[TL]   param  42: vcdnet/decoder/bn2/gamma:0 (512,)             float32_ref\n",
      "[TL]   param  43: vcdnet/decoder/bn2/moving_mean:0 (512,)             float32_ref\n",
      "[TL]   param  44: vcdnet/decoder/bn2/moving_variance:0 (512,)             float32_ref\n",
      "[TL]   param  45: vcdnet/decoder/conv3/W_conv2d:0 (3, 3, 1024, 512)    float32_ref\n",
      "[TL]   param  46: vcdnet/decoder/bn3/beta:0 (512,)             float32_ref\n",
      "[TL]   param  47: vcdnet/decoder/bn3/gamma:0 (512,)             float32_ref\n",
      "[TL]   param  48: vcdnet/decoder/bn3/moving_mean:0 (512,)             float32_ref\n",
      "[TL]   param  49: vcdnet/decoder/bn3/moving_variance:0 (512,)             float32_ref\n",
      "[TL]   param  50: vcdnet/decoder/conv4/W_conv2d:0 (3, 3, 768, 256)    float32_ref\n",
      "[TL]   param  51: vcdnet/decoder/bn4/beta:0 (256,)             float32_ref\n",
      "[TL]   param  52: vcdnet/decoder/bn4/gamma:0 (256,)             float32_ref\n",
      "[TL]   param  53: vcdnet/decoder/bn4/moving_mean:0 (256,)             float32_ref\n",
      "[TL]   param  54: vcdnet/decoder/bn4/moving_variance:0 (256,)             float32_ref\n",
      "[TL]   param  55: vcdnet/decoder/conv5/W_conv2d:0 (3, 3, 384, 128)    float32_ref\n",
      "[TL]   param  56: vcdnet/decoder/bn5/beta:0 (128,)             float32_ref\n",
      "[TL]   param  57: vcdnet/decoder/bn5/gamma:0 (128,)             float32_ref\n",
      "[TL]   param  58: vcdnet/decoder/bn5/moving_mean:0 (128,)             float32_ref\n",
      "[TL]   param  59: vcdnet/decoder/bn5/moving_variance:0 (128,)             float32_ref\n",
      "[TL]   param  60: vcdnet/decoder/conv6/W_conv2d:0 (3, 3, 192, 61)    float32_ref\n",
      "[TL]   param  61: vcdnet/decoder/bn6/beta:0 (61,)              float32_ref\n",
      "[TL]   param  62: vcdnet/decoder/bn6/gamma:0 (61,)              float32_ref\n",
      "[TL]   param  63: vcdnet/decoder/bn6/moving_mean:0 (61,)              float32_ref\n",
      "[TL]   param  64: vcdnet/decoder/bn6/moving_variance:0 (61,)              float32_ref\n",
      "[TL]   num of params: 18823732\n",
      "[TL]   [*] geting variables with vcdnet\n",
      "[TL]   got   0: vcdnet/conv1/W_conv2d:0   (7, 7, 121, 128)\n",
      "[TL]   got   1: vcdnet/interp/conv0/W_conv2d:0   (3, 3, 32, 64)\n",
      "[TL]   got   2: vcdnet/interp/conv1/W_conv2d:0   (3, 3, 16, 32)\n",
      "[TL]   got   3: vcdnet/interp/conv2/W_conv2d:0   (3, 3, 8, 16)\n",
      "[TL]   got   4: vcdnet/interp/conv3/W_conv2d:0   (3, 3, 4, 8)\n",
      "[TL]   got   5: vcdnet/interp/conv_final/W_conv2d:0   (3, 3, 8, 8)\n",
      "[TL]   got   6: vcdnet/interp/bn_final/beta:0   (8,)\n",
      "[TL]   got   7: vcdnet/interp/bn_final/gamma:0   (8,)\n",
      "[TL]   got   8: vcdnet/encoder/conv0/W_conv2d:0   (3, 3, 8, 64)\n",
      "[TL]   got   9: vcdnet/encoder/bn_0/beta:0   (64,)\n",
      "[TL]   got  10: vcdnet/encoder/bn_0/gamma:0   (64,)\n",
      "[TL]   got  11: vcdnet/encoder/conv1/W_conv2d:0   (3, 3, 64, 128)\n",
      "[TL]   got  12: vcdnet/encoder/bn1/beta:0   (128,)\n",
      "[TL]   got  13: vcdnet/encoder/bn1/gamma:0   (128,)\n",
      "[TL]   got  14: vcdnet/encoder/conv2/W_conv2d:0   (3, 3, 128, 256)\n",
      "[TL]   got  15: vcdnet/encoder/bn2/beta:0   (256,)\n",
      "[TL]   got  16: vcdnet/encoder/bn2/gamma:0   (256,)\n",
      "[TL]   got  17: vcdnet/encoder/conv3/W_conv2d:0   (3, 3, 256, 512)\n",
      "[TL]   got  18: vcdnet/encoder/bn3/beta:0   (512,)\n",
      "[TL]   got  19: vcdnet/encoder/bn3/gamma:0   (512,)\n",
      "[TL]   got  20: vcdnet/encoder/conv4/W_conv2d:0   (3, 3, 512, 512)\n",
      "[TL]   got  21: vcdnet/encoder/bn4/beta:0   (512,)\n",
      "[TL]   got  22: vcdnet/encoder/bn4/gamma:0   (512,)\n",
      "[TL]   got  23: vcdnet/encoder/conv5/W_conv2d:0   (3, 3, 512, 512)\n",
      "[TL]   got  24: vcdnet/encoder/bn5/beta:0   (512,)\n",
      "[TL]   got  25: vcdnet/encoder/bn5/gamma:0   (512,)\n",
      "[TL]   got  26: vcdnet/decoder/conv2/W_conv2d:0   (3, 3, 1024, 512)\n",
      "[TL]   got  27: vcdnet/decoder/bn2/beta:0   (512,)\n",
      "[TL]   got  28: vcdnet/decoder/bn2/gamma:0   (512,)\n",
      "[TL]   got  29: vcdnet/decoder/conv3/W_conv2d:0   (3, 3, 1024, 512)\n",
      "[TL]   got  30: vcdnet/decoder/bn3/beta:0   (512,)\n",
      "[TL]   got  31: vcdnet/decoder/bn3/gamma:0   (512,)\n",
      "[TL]   got  32: vcdnet/decoder/conv4/W_conv2d:0   (3, 3, 768, 256)\n",
      "[TL]   got  33: vcdnet/decoder/bn4/beta:0   (256,)\n",
      "[TL]   got  34: vcdnet/decoder/bn4/gamma:0   (256,)\n",
      "[TL]   got  35: vcdnet/decoder/conv5/W_conv2d:0   (3, 3, 384, 128)\n",
      "[TL]   got  36: vcdnet/decoder/bn5/beta:0   (128,)\n",
      "[TL]   got  37: vcdnet/decoder/bn5/gamma:0   (128,)\n",
      "[TL]   got  38: vcdnet/decoder/conv6/W_conv2d:0   (3, 3, 192, 61)\n",
      "[TL]   got  39: vcdnet/decoder/bn6/beta:0   (61,)\n",
      "[TL]   got  40: vcdnet/decoder/bn6/gamma:0   (61,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/train.py:109: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/train.py:113: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/capsule/code/vcdnet/train.py:114: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] creates ./sample/test/tubulin_40x_n11_[m30-30]_step1um_xl9_num120_sparse/ ...\n",
      "[TL] [*] creates ./checkpoint/tubulin_40x_n11_[m30-30]_step1um_xl9_num120_sparse/ ...\n",
      "[TL] [!] ./log/tubulin_40x_n11_[m30-30]_step1um_xl9_num120_sparse/ exists ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "040-000063.tif : (176, 176, 61)\n",
      "040-000063.tif : (16, 16, 121)\n",
      "HR dataset : (2358, 176, 176, 61)\n",
      "LF dataset: (2358, 16, 16, 121)\n",
      "\n",
      "Epoch:[0/200] iter:[5/2123] time: 4.174s, {'ln_loss': 0.8491743}}"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'test_loss_plt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/capsule/code/vcdnet/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/capsule/code/vcdnet/train.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, begin_epoch)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mevaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplchdr_lf\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mLF_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplchdr_target3d\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mHR_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ac450ffc1bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/capsule/code/vcdnet/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_test_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/capsule/code/vcdnet/train.py\u001b[0m in \u001b[0;36m_plot_test_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_plot_test_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loss_plt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'test_loss_plt'"
     ]
    }
   ],
   "source": [
    "use_cpu = True # set to False if a CUDA enabled GPU is available. Note: GPU is not supported in current code ocean environment\n",
    "\n",
    "trainer  = Trainer(training_dataset)\n",
    "trainer.build_graph(use_cpu)\n",
    "trainer.train(begin_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next\n",
    "Now we have a trained model. Navigate to the [predict notebook](./predict_demo.ipynb) to apply it to reconstruct a light field raw image into 3D stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}